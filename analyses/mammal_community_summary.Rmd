---
title: "Mammal Activity Summary"
output:
  html_document: default
  word_document: default
date: "2024-07-22"
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(
	echo = FALSE,
	message = FALSE,
	warning = FALSE
)
# setting all chunks not to display anything but output so i can easily knit and send to hillary

library(tidyverse)
library(car)
library(ggpubr)
library(ggprism) # paste pvalues
library(geosphere)
library(lubridate)
library(hms)
library(janitor)
library(kableExtra)
library(formattable)
library(webshot2)
library(vegan)
library(here)
library(RColorBrewer)
library(rstatix)
library(Polychrome) #package to make palettes witha shit ton of distinct colors

# set general ggplot theme:


```

# Catch All Markdown for Mammal Community and Activity Summary Figures and Stats
### Behind the Scenes
#### Pull and Clean Data
```{r data import and cleaning}
#### data versioning log ###
# 23 jul 2024: had to manually paste in some NVS photos with the correct date 
# 31 jul using what's hopefully final version, there will be new date issues I think


# let's see what kind of mess we're working with
mammals_unclean <- read_csv(here("data/WI_data_31jul2024/image_classifications_31jul2024.csv")) 


#unique(mammals_unclean$behavior)

mammals <- mammals_unclean %>%
  filter(class == "Mammalia") %>% 
  filter(!identified_by == "Computer vision") %>%  # removes about half the rows, hipefully from HROA
  
  # ugh annoying unclean inconsistent capitals
  mutate(filename = tolower(filename)) %>% 
  mutate(common_name = tolower(common_name)) %>% 
  
  # ugh ugh the filenames where i forgot to put a "_"
  mutate(filename = str_replace(filename, "pp17apr22", "pp_17apr22")) %>% 
  mutate(filename = str_replace(filename, "boatcam17apr22", "boat_17apr22")) %>% 
  mutate(filename = str_replace(filename, "pb28apr22", "pb_28apr22")) %>% 
  mutate(filename = str_replace(filename, "gov17apr22", "gov_17apr22")) %>% 
  mutate(filename = str_replace(filename, "nvs28apr22", "nvs_28apr22")) %>% 
  mutate(filename = str_replace(filename, "pl17apr22", "pl_17apr22")) %>%  
  mutate(filename = str_replace(filename, "cove17apr22", "cove_17apr22")) %>% 
  mutate(filename = str_replace(filename, "bc17apr22", "bc_17apr22")) %>%
  mutate(filename = str_replace(filename, "bc28apr22", "bc_28apr22")) %>%
  mutate(filename = str_replace(filename, "pd28apr22", "pd_28apr22")) %>% 
  mutate(filename = str_replace(filename, "gov_12nov22", "big_12nov22")) %>%
  mutate(filename = str_replace(filename, "gov_17sep", "big_17sep")) %>%

    # also inconsistent sitenames:
  mutate(sitename = case_when(deployment_id == "Boneyard 09/07/2022" ~ "Boneyard Cam",
                              deployment_id == "Old Fencepost Cam April 2022" ~ "Old Fencepost Cam",
                              deployment_id == "Percos Post March 2022" ~ "Percos Post Cam",
                              deployment_id == "seawall cam" ~ "Seawall Cam",
                              deployment_id == "Boathouse May - July 2022" ~ "Boathouse Cam",
                              deployment_id == "Saucito" ~ "Saucito Cam",
                              .default = as.character(deployment_id))) %>% 
  
  mutate(deployment_id = paste0(str_extract(filename, "[^_]*_[^_]*"))) %>%  # return only the first 2 substrings (e.g. cam name and dmy) of the filenames - this is very sloppy and I hate it but oh well
  
  #English translation:
    # [^_]* = as many non-underscore characters as possible
    # _ = an underscore
    # [^_]* = as many non-underscore characters as possible
    # [...] is a character class. [abc] means "a or b or c", and [^abc] means anything but a or b or c.
  
  # editing the csv messed up the dates which were so nice before
  #mutate(timestamp = as.POSIXct(timestamp, tz=Sys.timezone()))# %>% # THIS IS SUPER INCONSISTENT, SOMETIMES THE DATA IMPORTS WITH NORMAL DATES, SOMETIMES NOT
  
  ## main thing to do is clean up the behavior column which is a mess. Specifically need to separate all of the "holding" etc behaviors from the item
  mutate(behavior = tolower(behavior)) %>% 
  mutate(behavior_clean = str_replace(behavior, "carrying", "carrying;")) %>% 
  mutate(behavior_clean = str_replace(behavior_clean, "holding food", "holding;")) %>%
  mutate(behavior_clean = str_replace(behavior_clean, "holding ", "holding;")) %>% 
  mutate(behavior_clean = str_replace(behavior_clean, "eating ", "eating;")) %>%
  mutate(behavior_clean = str_replace(behavior_clean, "foraging", "foragin")) %>% # i think this is the only way to do this given the nature of this typo
  mutate(behavior_clean = str_replace(behavior_clean, "foragin", "nose to ground")) %>%
  mutate(behavior_clean = str_replace(behavior_clean, "flighting", "fighting")) %>%
  mutate(behavior_clean = str_remove(behavior_clean, "\\[")) %>%
  mutate(behavior_clean = str_remove(behavior_clean, "\\]")) %>%
# there are many more behaviors to clean but for now, moving on to cleaning identifications because we are likely not going to focus on behavior


  separate(behavior, c("behavior_clean", "prey_or_item"), sep = ";", remove = FALSE) %>% 
  separate(behavior, c("behavior1", "behavior2"), sep = ",", remove = TRUE) %>%  # separates out behaviors if there are multiple
  
  uncount(number_of_objects, # "uncounts" i.e. makes specified number of copies of the row based on the # in how_many
          # we are basically multipling the number captures of animals by the number of animals in the capture - this is fine...
          
          .remove = FALSE #check your work by including .remove = FALSE... this keeps the column where the #of copies to make was stored. default is to delete it
          ) %>% 
 
# going to make some assumptions about IDs here:
  mutate(common_name = case_when(common_name == "canis species" ~ "coyote",
                        common_name == "canine family" ~ "coyote",
                        common_name == "cervus species" ~ "mule deer",
                        common_name == "cervidae family" ~ "mule deer",
                        common_name == "cetartiodactyla order" ~ "mule deer",
                        common_name == "odocoileus species" ~ "Mule Deer",
                        common_name == "elk" ~ "mule deer", # def not an elk
                        common_name == "even-toed ungulate" ~ "mule deer",
                        common_name == "pronghorn" ~ "mule deer", 
                        common_name == "vulpes species" ~ "grey gox",
                        common_name == "lepus species" ~ "brush rabbit", 
                        common_name == "domestic cat" ~ "bobcat", # double checked, def a bobcat
                        common_name == "eurasian lynx" ~ "bobcat",
                        common_name == "domestic pig" ~ "feral hog", 
                        common_name == "wild boar" ~ "feral hog",
                        common_name == "sus species" ~ "feral hog",
                        common_name == "neotoma species" ~ "rat/mouse",
                        common_name == "martes species" ~ "weasel",
                        common_name == "ursus species" ~ "american black bear",
                        common_name == "nutria" ~ "rat/mouse", # for now, until we determine if that thing is actually a nutria!
                        common_name == "western gray squirrel" ~ "california ground squirrel",
                        common_name == "brown rat" ~ "rat/mouse",
                        common_name == "woodrat or rat or mouse species" ~ "rat/mouse",
                        common_name == "rodent" ~ "rat/mouse",
                        common_name == "california mouse" ~ "rat/mouse",
                        common_name == "house mouse" ~ "rat/mouse",
                        common_name == "muridae family" ~ "rat/mouse",
                        common_name == "geomyidae family" ~ "gopher",
                        common_name == "kit fox" ~ "coyote", # def not a kit fox 
                        common_name == "white-tailed deer" ~ "mule deer",
                        common_name == "domestic cattle" & deployment_id == "Jalama 2" ~ "feral hog", # went and checked and computer IDd some pigs as cows. fixing for now in post, will fix later in WI [4aug23]
                        common_name == "white-tailed jackrabbit" ~ "coyote", # based on pics these are always yotes
                        common_name == "black-tailed jackrabbit" ~ "coyote", # checked and all jackrabbit IDs are coyotes
                        common_name == "mammal" ~ "unidentified mammal",
                        common_name == "carnivorous mammal" ~ "unidentified mammal",
                        .default = as.character(common_name)
                        )
         ) %>% 
# need to remove domestics, marine mammals, humans, sheep, mouflon?? and other weird IDs
  filter(common_name != "mouflon", 
         common_name != "domestic sheep",
         common_name != "domestic cattle",
         common_name != "equus species",
         common_name != "domestic dog",
         common_name != "human",
         common_name != "human - camera trapper",
         common_name != "human - biker",
         common_name != "domestic cow",
         common_name != "domestic horse",
         common_name != "human",
         common_name != "human-camera trapper",
         common_name != "human-pedestrian",
         common_name != "californian sea lion",
         common_name != "harbor seal"
         ) 

spp <- unique(mammals$common_name)

```

#### Fix Messed Up Dates in Dataset
```{r fixing dates}

# we will first pull out just the incorrect dates, which are luckily all before 2020
fix_dates <- mammals %>% 
    ## make the dates nice
  mutate(year = year(timestamp)) %>% 
  filter(year == 2017 | 
           year == 2018 | 
           year == 2020 | 
           year == 2021 |
           deployment_id == "boat_16oct22" |
           deployment_id == "boat_17apr22" |
           deployment_id == "boat_17sep22" |
           deployment_id == "boat_5apr22" )

  #filter(year<=2021) # for now we have to make this more complicated because WI randomly changed dates of some deployments

# now we need to figure out what the corrections are, and for that we will need this dataset: https://docs.google.com/spreadsheets/d/1-gLml8H2stC2Va9H42tWLylx-5f1r8m4BDMKnsBUHl8/edit?usp=sharing (downloaded csv of one tab)
timestamp_corrections1 <- read_csv(here("data/incorrect_timestamps.csv")) 

timestamp_corrections <- timestamp_corrections1 %>% 
  rename(deployment_id = filename) %>% 
  mutate(real_start = mdy_hm(real_start)) %>% 
  mutate(recorded_start = mdy_hm(recorded_start)) %>% 
  mutate(real_end = mdy_hm(real_end)) %>% 
  mutate(recorded_end = mdy_hm(recorded_end)) %>% 
  mutate(correction = difftime(real_start, recorded_start, units = "mins")) %>%  #gives us the # minutes to add to the recorded time to correct the timestamp
  dplyr::select(deployment_id, correction)

#test_correct <- timestamp_corrections %>% 
#  mutate(calculated_end = recorded_end + correction) # it works!!

# now we can apply to the timestamp on each incorrect date, I hope!

## by matching on deployment ID
fixed_dates <- left_join(fix_dates, timestamp_corrections, by = join_by(deployment_id)) %>%  # pop the correction time in to the deployments it applies to
  # overwrite timestamp column with correct date
  mutate(timestamp = timestamp + correction) %>% 
  dplyr::select(!c(correction, year)) # take these bad bois out
  

# join the two datasets back together!
mammals_correctdates <- mammals %>% 
    filter(year(timestamp) == 2022 | 
           year(timestamp) == 2023 ) %>% 
    filter(deployment_id != "boat_16oct22") %>% 
    filter(deployment_id != "boat_17apr22") %>% 
    filter(deployment_id != "boat_17sep22") %>% 
    filter(deployment_id != "boat_5apr22" ) # need to remove the bad dates from the original dataset
  #filter(year(timestamp)>2021) # no longer this simple

#mammals_incorrectdates <- mammals %>% 
#  filter(year(timestamp)<=2021) # just to check (right now same # rows as 'fixed dates' so that's great)

## and do some downstream cleaning like removing useless columns
mammals_fixed_dates <- rbind(mammals_correctdates, fixed_dates) %>% 
  dplyr::select(sitename, deployment_id, filename, identified_by, class, order, family, genus, species, common_name, timestamp, number_of_objects, behavior1, behavior2, prey_or_item) %>% 
  mutate(day = day(timestamp)) %>% 
  mutate(month = month(timestamp)) %>% 
  mutate(year = year(timestamp)) %>% 
  separate(timestamp, c("date", "time"), sep = " ") %>% 
  mutate(common_name = tolower(common_name))

```

#### We should add in some metadata for sorting and analysis purposes
```{r add in metadata}

######################## "monthly" deployment data ######################## 

deployment_data_original <- read_csv(here("data/cam_deployment_data_FIXED_DATES_29jul2024.csv")) %>% 
  clean_names() %>% 
  rename(sitename = camera_name, 
         maint_month = month,
         deployment_id = filename_prefix,
         property = location) %>% 
  
  # need to rename some file prefixes to match what is in mammals post-cleaning (ie adding underscores)
  mutate(deployment_id = str_replace(deployment_id, "pp17apr22", "pp_17apr22")) %>% 
  mutate(deployment_id = str_replace(deployment_id, "boatcam17apr22", "boat_17apr22")) %>% 
  mutate(deployment_id = str_replace(deployment_id, "pb28apr22", "pb_28apr22")) %>% 
  mutate(deployment_id = str_replace(deployment_id, "gov17apr22", "gov_17apr22")) %>% 
  mutate(deployment_id = str_replace(deployment_id, "nvs28apr22", "nvs_28apr22")) %>% 
  mutate(deployment_id = str_replace(deployment_id, "pl17apr22", "pl_17apr22")) %>% 
  mutate(deployment_id = str_replace(deployment_id, "cove17apr22", "cove_17apr22")) %>% 
  mutate(deployment_id = str_replace(deployment_id, "bc28apr22", "bc_28apr22")) %>% 
  mutate(deployment_id = str_replace(deployment_id, "bc17apr22", "bc_17apr22")) %>%
  mutate(deployment_id = str_replace(deployment_id, "pd28apr22", "pd_28apr22")) %>% 
  filter(!is.na(deployment_id)) %>% # will sort out deployments that don't have an ID because I manually added these in
  
  # need to fix days active column:
  mutate(day_end = mdy_hm(day_end)) %>% 
  mutate(day_start = mdy_hm(day_start)) %>% 
  mutate(days_active_calcd = difftime(day_end, day_start, units = "days")) %>% 
  
  filter(exclude != "y") # also need to take out the deployments I found a reason to exclude (tipped to sky etc)
  
# also need to figure out how many days active per MONTH

deployment_data <- deployment_data_original %>%   
  mutate(each_date = map2(day_start, day_end, ~seq(from = .x, to = .y, by = "day"))) %>% # creates a list of all dates between each start and end date (each row)
  unnest(each_date) %>% # expands that list to be one row per date
  mutate(month = month(each_date)) %>%  # extracts month from the dates
  group_by(deployment_id, month) %>% 
  mutate(days_per_month = n()) %>% # counts number of active days per month, assuming full activity between start and end date
# works if i want to keep all rows i just created but i dont, i want to summarize
  distinct(deployment_id, month, .keep_all = TRUE) %>%  # lets me keep only rows that are unique for combo of deployment id and month, while keeping all other columns
  dplyr::select(!each_date) # no longer need this
  

######################## add on human data to montly deployment data #########################
humans_est <- read_csv(here("data/human_activity.csv")) %>%  # current best estimate of sitely, monthly human activity (made 8/3/2023)
  mutate(month = month(dmy(date))) %>% 
  rename(sitename = site,
         n_human_shots = n,
         human_seconds = seconds) %>% 
  dplyr::select(sitename, month, n_human_shots, human_seconds)

deployment_data_humans <- left_join(deployment_data, humans_est, by = join_by(sitename, month)) %>% 
  # fill in zeros for where there "is no human activity" - apparently, must check this
  mutate(human_seconds = case_when(is.na(human_seconds) ~ 0,
                                   TRUE ~ as.numeric(human_seconds))) %>% 
  mutate(sitename = fct_relevel(sitename, c("Boathouse Cam", "Ladrones Cam", "Saucito Cam", "Water Canyon Cam", "Not Water Canyon Cam", "Morida Cam","RIZ Cam", "RIZ Cam Backup", "RIZ Cam S Canyon", "Sudden Canyon Cam", "Old Fencepost Cam", "Jolluru Cam", "Short Canyon Cam", "Jalama Cam", "Jalama 2 Cam", "Cojalama Cam", "Cojo Gate Cam", "Cojo Canyon Cam", "Seawall Cam", "Black Canyon Cam", "North Beach Fort Cam", "North Vista Spring Cam", "North Beach Canyon Cam", "Boneyard Cam", "Cove Cam", "Govies Cliff Cam", "Big Cojo Cam", "Percos Boat Cam", "Percos Driftwood Cam", "Wood Canyon Cam", "Percos Beach Cam", "Percos Log Cam", "Percos Post Cam", "Damsite Creek Cam")))

######################## site metadata #########################

metadata <- read_csv(here("data/site_metadata.csv")) %>% # NOT camera_metadata.csv (site_metadata is in camtrapR format)
  clean_names() %>% 
  filter(!str_detect(camera_id, "2")) %>%  # removing second cameras from the metadata (these were placed when the originals were stolen, but in the same place)
  dplyr::select(station, utm_x, utm_y, cam_brand, property, habitat_adjacent, habitat_secondary, iz_type, burst_settings) %>% 
  rename(sitename = station)

#### add in distance to Jalama (as center of human activity) using package geosphere ####

jalama_loc <- tibble(utm_x = 34.510480, utm_y = -120.501467) 
jalama_mtx <- cbind(jalama_loc$utm_y, jalama_loc$utm_x) # dist function requires that both distances be in matrix form, this is one way to do that apparently
# help doc example doesn't say this is necessary but oh well

metadata2 <- metadata %>% 
  mutate(dist_jalama = (distVincentyEllipsoid(cbind(utm_y, utm_x), jalama_mtx))/1000) %>% # dist returns shortest distance in meters as default
  filter(sitename != "North Jalama") # for now, so list matches the data we're actually using

######################## combine and add metadata to mammals data #########################

# this combines deployment (now we've made it monthly) records with metadata for each site
metadata_by_deployment <- left_join(deployment_data_humans, metadata2, by = join_by(property, sitename)) %>% 
  dplyr::select(property, sitename, deployment_id, dist_jalama, imgs_on_sd, days_active_calcd, days_per_month, month, exclude, utm_x, utm_y, human_seconds, habitat_adjacent, habitat_secondary, iz_type, burst_settings, cam_brand) %>% 
  filter(exclude == "n") %>% 
  filter(!is.na(deployment_id)) # filters out all the deployments that haven't been reviewed because i don't put in filename prefix if it hasn't been reviewed on WI

# cross checking that all deployments in the metadata are present in the mammals df and vice versa
deployments_from_mammalsdf <- mammals_fixed_dates %>% 
  distinct(deployment_id, month, .keep_all = TRUE)

missing_deployments <- anti_join(deployments_from_mammalsdf, metadata_by_deployment, by = c("deployment_id", "month"))  # anti_join() return all rows from x without a match in y  ]

# for some reason this dataframe construction is duplicating some rows .... causing downstream issues, so we are going to use a dataframe BY MONTH instead and then match to mammals using combo of site and month

metadata_by_month <- metadata_by_deployment %>% 
  distinct(sitename, month, days_per_month, .keep_all = TRUE) %>% # only unique combinations of site, month, and days deployed because some months were split over deployments
  # so now we need to sum days deployed when they're split across multiple deployments but in the same month:
  group_by(property, sitename, dist_jalama, utm_x, utm_y, habitat_adjacent, habitat_secondary, iz_type, burst_settings, cam_brand, # none of these change over the course of the project
           human_seconds, month) %>% # these are how we want to sum days per month (sums across deployments)
  summarise(days_per_month = sum(days_per_month)) %>% 
  unite(sitemonth_id, c("sitename", "month"), sep = ".", remove = FALSE) %>% 
  mutate(sitename = fct_relevel(sitename, c("Boathouse Cam", "Ladrones Cam", "Saucito Cam", "Water Canyon Cam", "Not Water Canyon Cam", "Morida Cam","RIZ Cam", "RIZ Cam Backup", "RIZ Cam S Canyon", "Sudden Canyon Cam", "Old Fencepost Cam", "Jolluru Cam", "Short Canyon Cam", "Jalama Cam", "Jalama 2 Cam", "Cojalama Cam", "Cojo Gate Cam", "Cojo Canyon Cam", "Seawall Cam", "Black Canyon Cam", "North Beach Fort Cam", "North Vista Spring Cam", "North Beach Canyon Cam", "Boneyard Cam", "Cove Cam", "Govies Cliff Cam", "Big Cojo Cam", "Percos Boat Cam", "Percos Driftwood Cam", "Wood Canyon Cam", "Percos Beach Cam", "Percos Log Cam", "Percos Post Cam", "Damsite Creek Cam")))

mammals_clean <- left_join(mammals_fixed_dates, metadata_by_month, by = join_by(sitename, month)) %>% 
  #rename(sitename = sitename.x) %>%  #got two of these in the join
  #dplyr::select(!sitename.y) %>% 
  filter(!is.na(property)) # right now (23 jul 2024) this filters out HROA data because there's not metadata for those cams

# the above SHOULD pop on monthly metadata to each observation based on its observed month and site

```


### Ok! Now we can organize and play with the nice clean data (I hope). A summary:
(all numbers have been rounded UP to the nearest integer, except percentages)
```{r some tables}

########################################################################################
bursts <- metadata %>% 
  dplyr::select(sitename, burst_settings) # make a mini dataframe just for burst settings

######### make table of total images by sitename ###########
count_site <- deployment_data %>%
  ungroup() %>% 
  distinct(sitename, deployment_id, imgs_on_sd) %>% # WHY is this preserving month when i don't want it to # needed to ungroup deployment_data
  group_by(sitename) %>%  # makes a summary table of # images of humans per deployment_id
  summarise(n_images_total = sum(imgs_on_sd)) %>% 
  left_join(., bursts, by = join_by(sitename)) %>% 
  mutate(triggers = ceiling(n_images_total/burst_settings) # ceiling rounds UP
    ) %>% 
  dplyr::select(sitename, #n_images_total, 
                triggers)
  
########################################################################################

######### make table of animal activity ( = incidences) by species summed across all deployment_ids ###########
count_species <- mammals_clean %>%
  count(common_name) %>%  # makes a summary table of # images per species per deployment_id
  rename(n_images = n) # rename n to be more informative

########################################################################################

######### make table of animal activity ( = incidences) by species and deployment_ids ###########
count_species_site <- mammals_clean %>%
  count(sitename, common_name) %>%  # makes a summary table of # images per species per deployment_id
  rename(n_images = n) # rename n to be more informative

########################################################################################

######### make table of TOTAL wild animal activity ( = incidences that weren't empty, people, or domestic animals) summed across deployment_ids ###########
count_mam_images <- mammals_clean %>%
  filter(common_name != "empty") %>% 
  filter(common_name != "person")%>% 
  filter(!str_detect(common_name, "human"))%>% 
  filter(!str_detect(common_name, "domestic"))%>% 
  filter(common_name != "equestrian") %>% 
  count(sitename) %>%  # makes a summary table of # images per common_name per site
  rename(n_animal_imgs = n) # rename n to be more informative

count_activity <- count_mam_images %>% 
  # need to divide images by respective bursts:
  left_join(., bursts, by = join_by(sitename)) %>% 
  mutate(activity_seconds = ceiling(n_animal_imgs/burst_settings)) %>% # again, rounds up
  dplyr::select(sitename, activity_seconds)

########################################################################################

######### make table of total human activity summed across deployment_ids ###########
human_activity <- mammals_clean %>%
  distinct(sitename, month, .keep_all = TRUE) %>% #makes it so that sum doesn't artificially sum 
  group_by(sitename) %>%  # makes a summary table of # images of humans per deployment_id
  summarise(human_activity = ceiling(sum(human_seconds)))

########################################################################################

######### make table number of wildlife species at each site ###########
num_species_site <- mammals_clean %>%
  filter(!str_detect(common_name, "human"))%>% 
  filter(!str_detect(common_name, "domestic"))%>%
  group_by(sitename) %>%  # makes a summary table of # species per deployment_id
  summarize(num_species = n_distinct(sitename, common_name)) # how many unique species at each site
  
########################################################################################

```

```{r visualizations of data over time, echo=FALSE, message=FALSE, warning=FALSE}

## Temporal visualizations are more tricky because some of the cameras have date errors
### for now we will just filter incorrect dates out

######### make table of trap nights by deployment_name ###########

# trap night is defined as every night a camera is active, so this isn't really trap nights, its "this camera was triggered nights"

trigger_nights_site <-  mammals_clean%>% 
  group_by(sitename) %>% 
  summarize(trigger_nights = n_distinct(sitename, date)) # how many unique dates at each site

# we already calculated actual trap nights, it should be in the full metadata_by_deployment
trapnights_site <- metadata_by_deployment %>% 
  ungroup() %>% 
  distinct(sitename, deployment_id, days_active_calcd) %>% 
  group_by(sitename) %>% 
  summarise(trapnights = sum(days_active_calcd)) %>% 
  mutate(trapnights = ceiling(as.numeric(trapnights))) # again, rounds up

# also interested in trapnights per month for each site
trapnights_month <- mammals_clean %>% 
  group_by(sitename, month) %>% 
  summarize(start = min(date),
            end = max(date),
            trapnights_w_photos = n_distinct(date),
            trapnights = difftime(max(date), min(date), units = "days")
            ) %>% 
  mutate(trapnights = ceiling(as.numeric(trapnights))) # rounding up again
  
#view(trapnights_month)
########################################################################################


######### make table of species by month ###########
species_month <- mammals_clean %>%
  count(month, year, common_name) %>%  # makes a summary table of # images per species per month
# includes count of empties
  rename(n_imgs = n) # rename n to be more informative

########################################################################################

######### make table of unadjusted image count by site by date ###########
count_site_date <- mammals_clean %>%
  count(sitename, month)  # makes a summary table of # animal sightings per species per deployment_id per month

# to check a below table, don't use
count_site_date_sp <- mammals_clean %>%
  count(sitename, month, common_name)  # makes a summary table of # animal sightings per species per deployment_id per month
  
########################################################################################


######### make table of total images summed across all deployment_ids by date ###########
count_month <- mammals_clean %>%
  count(month) # makes a summary table of # animal images per month
########################################################################################


######### make table of animal activity ( = incidences adjusted by burst number and corrected for by trap nights) by date and site and species ###########
activity_site_month_sp <- left_join(mammals_clean, trapnights_month, by = join_by(sitename, month)) %>% # first append monthly trapnights to full dataset, checked and it doesn't delete any rows
  ungroup()%>%
  group_by(property,sitename, month, trapnights, burst_settings, common_name) %>% 
  summarize(total_captures = n()
    #total_captures = sum(number_of_objects), #  this isn't returning the same # as counting rows because sometimes the value isn't 1!!!
            ) %>% # had a hard time with the final columns so I'm tossing it out into a mutate:
  mutate(activity_seconds = ceiling(total_captures/burst_settings))%>%  # adjusts # of captures by the number of images taken in a burst (8 or 10), ceiling rounds UP)
  # need to make trapnights numeric integers in order to adjust by them
  mutate(trapnights = case_when(trapnights == "0.000000 days" ~ 1,
                                TRUE ~ as.numeric(trapnights))) %>% 
  mutate(trapnights = case_when(trapnights == 0 ~ 1,
                                TRUE ~ as.numeric(trapnights))) %>%
  mutate(seconds_by_trapnight = activity_seconds/trapnights) %>% 

  unite("sitemonth_id", sitename, month, sep = ".", remove = FALSE)
  
######## some numbers for dissertation ch ########

### total seconds of activity ###
seconds_all <- sum(activity_site_month_sp$activity_seconds)
second_per_trapnight <- sum(activity_site_month_sp$seconds_by_trapnight)

### percent of total activity - coyotes ###
coyotes <- activity_site_month_sp %>% 
  filter(common_name == "coyote") 

total_yotes_sec <- sum(coyotes$activity_seconds)
yotes_per_trapnight <- sum(coyotes$seconds_by_trapnight)

percent_yotes <- total_yotes_sec/seconds_all
percent_yotes

### percent of total activity - pigs ###
pigs <- activity_site_month_sp %>% 
  filter(common_name == "feral hog") 

total_pigs_sec <- sum(pigs$activity_seconds)
pigs_per_trapnight <- sum(pigs$seconds_by_trapnight)

percent_pigs <- total_pigs_sec/seconds_all
percent_pigs

### percent of total activity - deer ###
deer <- activity_site_month_sp %>% 
  filter(common_name == "mule deer") 

total_deer_sec <- sum(deer$activity_seconds)
deer_per_trapnight <- sum(deer$seconds_by_trapnight)

percent_deer <- total_deer_sec/seconds_all
percent_deer

### percent of total activity - rodents ###
rats <- activity_site_month_sp %>% 
  filter(common_name == "rat/mouse") 

total_rats_sec <- sum(rats$activity_seconds)
rats_per_trapnight <- sum(rats$seconds_by_trapnight)

percent_rats <- total_rats_sec/seconds_all
percent_rats
  
########################################################################################
######### make table one big summary table by site ###########

camera_activity_summary <- full_join(count_site, count_activity,  by = join_by(sitename)) %>% 
  full_join(human_activity, by = join_by(sitename)) %>%
  full_join(num_species_site, by = join_by(sitename)) %>% 
  full_join(trapnights_site, by = join_by(sitename)) %>% 
  filter(sitename != "Big Cojo Closeups Only", 
         sitename != "Percos Boat Rodents") %>% 
  mutate(percent_animals = (activity_seconds/triggers)) %>% 
  mutate(percent_animals = percent(percent_animals)) %>%  # formattable::percent() formats as percent
  #mutate_if(is.numeric, ceiling()) %>% #format, digits=2,nsmall = 0) %>% # fixed these upstream
  relocate(trapnights, .before = triggers) %>% 
  mutate(sitename = fct_relevel(sitename, c("Boathouse Cam", "Ladrones Cam", "Saucito Cam", "Water Canyon Cam", "Not Water Canyon Cam", "Morida Cam","RIZ Cam", "RIZ Cam Backup", "RIZ Cam S Canyon", "Sudden Canyon Cam", "Old Fencepost Cam", "Jolluru Cam", "Short Canyon Cam", "Jalama Cam", "Jalama 2 Cam", "Cojalama Cam", "Cojo Gate Cam", "Cojo Canyon Cam", "Seawall Cam", "Black Canyon Cam", "North Beach Fort Cam", "North Vista Spring Cam", "North Beach Canyon Cam", "Boneyard Cam", "Cove Cam", "Govies Cliff Cam", "Big Cojo Cam", "Percos Boat Cam", "Percos Driftwood Cam", "Wood Canyon Cam", "Percos Beach Cam", "Percos Log Cam", "Percos Post Cam", "Damsite Creek Cam"))) %>%  
  arrange(sitename)

pretty_summary <- kable(camera_activity_summary
      ,col.names = c("Camera Location (N to S)", "Number of Active Trap Nights", "Total Triggers" ,  "Seconds of Mammal Activity", "Number of Human Sightings", "Number of Unique Mammal Species",  "Percent of Triggers Containing Mammals")
      )

pretty_summary

```
### We can also visualize effort, or how many average nights the cameras were active per month across the year of sampling
In December 2022 only one camera was running (or rather, they were all running but most got washed away or the data was unusable because of storms)
 
```{r camera trap nights by month}

effort_plot <- trapnights_month %>% 
  mutate(month = month(month, label = TRUE)) %>% 
  ggplot(., aes(x = month, y = trapnights))+
  geom_boxplot() +
  theme_classic() +
  ylab("Mean Trapnights")+
  xlab("Month (2022)")

effort_plot
```
 
### Is there a seasonal effect on human activity? Probably!
```{r human activity by month}

# deployment_data_humans has monthly human data
seasonal_human_activity_plot <- deployment_data_humans %>% 
  mutate(month = month(month, label = TRUE)) %>%  
  mutate(standardized_humans = human_seconds/days_per_month) %>% 
  group_by(month) %>% 
  summarise(human_seconds_all = sum(standardized_humans)) %>%
  
  ggplot(., aes(x = month, y = human_seconds_all))+
  geom_bar(stat = "identity")

seasonal_mean_humans_plot <- deployment_data_humans %>% 
  mutate(month = month(month, label = TRUE)) %>%  
  mutate(standardized_humans = human_seconds/days_per_month) %>% 
  
  ggplot(., aes(x = month, y = standardized_humans))+
  scale_y_continuous(limits = c(0, 15))+
  geom_boxplot(outlier.shape = NA) # makes crazy jalama july outlier (600 seconds!) go away haha

seasonal_mean_humans_plot
```
### Does human activity actually concentrate around Jalama? Are there other hotspots of or refuges from human activity?
```{r human activity in space}

human_activity_inspace <- deployment_data_humans %>% 
  mutate(sitename = fct_relevel(sitename, c("Boathouse Cam", "Ladrones Cam", "Saucito Cam", "Water Canyon Cam", "Not Water Canyon Cam", "Morida Cam","RIZ Cam", "RIZ Cam Backup", "RIZ Cam S Canyon", "Sudden Canyon Cam", "Old Fencepost Cam", "Jolluru Cam", "Short Canyon Cam", "Jalama Cam", "Jalama 2 Cam", "Cojalama Cam", "Cojo Gate Cam", "Cojo Canyon Cam", "Seawall Cam", "Black Canyon Cam", "North Beach Fort Cam", "North Vista Spring Cam", "North Beach Canyon Cam", "Boneyard Cam", "Cove Cam", "Govies Cliff Cam", "Big Cojo Cam", "Percos Boat Cam", "Percos Driftwood Cam", "Wood Canyon Cam", "Percos Beach Cam", "Percos Log Cam", "Percos Post Cam", "Damsite Creek Cam"))) %>%
  mutate(month = month(month, label = TRUE)) %>%  
  mutate(standardized_humans = human_seconds/days_per_month) %>% 
  
  ggplot(., aes(y = standardized_humans, x = sitename)) +
  geom_boxplot(aes(fill = property),
    outlier.shape = NA # makes crazy jalama july outlier (600 seconds!) go away haha)
    ) + 
  scale_y_continuous(limits = c(0, 125))+
  theme_classic()+
  ylab("Human Activity (Seconds) Per Trapnight")+
  xlab("Sites (North to South") +
  theme(axis.text.x = element_text(angle = 45, 
                                   hjust = 1, 
                                   size = 7),
        axis.text.y = element_text(size = 10),
        axis.title.y = element_text(size = 10))
  
human_activity_inspace

#png(here("figures/humans_inspace_trunc.png"), width = 10, height = 6, units = "in", pointsize = 12, res = 1000)
#human_activity_inspace
#dev.off()

```

### Let's see if this is statistically significant (difficult because some of these are zeros)
```{r}
human_activity_2 <- deployment_data_humans %>% # no idea why we need the other human_activity but whatever
  mutate(standardized_humans = human_seconds/days_per_month)

### but we can check normality anyway
ggdensity(human_activity_2$standardized_humans)
ggqqplot(human_activity_2$standardized_humans)

## jesus, so not normal

## how about equal variances- Levene's test is robust to departures from normality
leveneTest(standardized_humans ~ sitename, data = human_activity_2)
fligner.test(standardized_humans ~ sitename, data = human_activity_2) #ok yeah very unequal variances even with most robust to non-normality test

#humanova <- aov(standardized_humans ~ property, data = human_activity_2)
#summary(humanova)
#plot(humanova)

# we will run a kruskal-wallis to detect differences between the three properties

human_activity_2 %>% 
  group_by(property) %>% 
  get_summary_stats(standardized_humans, type = "common") 

ggboxplot(human_activity_2, x = "property", y = "standardized_humans")

all_human_sec <- sum(human_activity_2$human_seconds)

humans_kw <- human_activity_2 %>% 
  ungroup() %>% 
  kruskal_test(standardized_humans ~ property)

humans_esize <- human_activity_2 %>% 
  ungroup() %>% 
  kruskal_effsize(standardized_humans ~ property)

humans_pairwise <- human_activity_2 %>% 
  ungroup() %>% 
  dunn_test(standardized_humans ~ property, p.adjust.method = "bonferroni")
```


### Finally, let's get an idea of mammal beach activity/detection, standardized by effort, across the entire year
```{r relative abundance}
########## general mammal relative activity-seconds, NOT standardized by trap night ##########

######### plot #########
IDcolors <- alphabet.colors(15) # we have 15 spp
names(IDcolors) <- NULL

countbyspecies <- ggplot(count_species, aes(x = reorder(common_name, -n_images), n_images)) + # reorders so that it displays bars in descending order of count
  geom_bar(aes(fill = common_name), stat = "identity") + # so i can pass a value to the bar instead of having ggplot count for me
  scale_fill_manual(values = IDcolors)+
  theme_classic()+
  theme(axis.text.x = element_text(angle = 45, 
                                   hjust = 1, 
                                   size = 7),
        axis.text.y = element_text(size = 10),
        axis.title.y = element_text(size = 10),
        axis.title.x = element_blank())+
  guides(fill=guide_legend(ncol=2, # splits long ass legend into two cols
                           title = "Mammal Species") 
         )+
  ylab("Number of Images")+
  xlab("Species")

countbyspecies

### saving ####

png(here("figures/species_freq.png"), width = 10, height = 6, units = "in", pointsize = 12, res = 1000)
countbyspecies
dev.off()

########## general mammal relative activity-seconds, standardized by burst and trap night ##########

adj_countbyspecies <- activity_site_month_sp %>% 
  group_by(common_name) %>% 
  summarise(total_adj_activity = sum(seconds_by_trapnight),
            total_seconds = sum(activity_seconds)) %>% 
  ggplot(., aes(x = reorder(common_name, -total_adj_activity), total_adj_activity)) +
  # ggplot(., aes(x = reorder(common_name, -total_seconds), total_seconds)) + # to check
  geom_bar(aes(fill = common_name), stat = "identity") + # so i can pass a value to the bar instead of having ggplot count for me
  scale_fill_manual(values = IDcolors)+
  theme_classic()+
  theme(axis.text.x = element_text(angle = 45, 
                                   hjust = 1, 
                                   size = 7),
        axis.text.y = element_text(size = 10),
        axis.title.y = element_text(size = 10),
        axis.title.x = element_blank())+
  guides(fill=guide_legend(ncol=2, # splits long ass legend into two cols
                           title = "Mammal Species") 
         )+
  ylab("Activity Seconds Per Trap Night")+
  xlab("Species")

png(here("figures/species_freq_bytrapnight.png"), width = 10, height = 6, units = "in", pointsize = 12, res = 1000)
adj_countbyspecies
dev.off()
  
```


```{r activity by season/month}

### first what does it look like with no standardization
seasonal_activity_plot_NS <- activity_site_month_sp %>% 
  mutate(month = month(month, label = TRUE)) %>%  
  group_by(month) %>% 
  summarise(all_mammals = sum(activity_seconds)) %>% 
  ggplot(., aes(x = month, y = all_mammals)) +
  geom_bar(stat = "identity")+
  ylab("Seconds of Mammal Activity, unadjusted")+
  xlab("Month (2022)")


seasonal_activity_plot <- activity_site_month_sp %>% 
  mutate(month = month(month, label = TRUE)) %>%  
  group_by(month) %>% 
  summarise(all_mammals = sum(seconds_by_trapnight)) %>% 
  ggplot(., aes(x = month, y = all_mammals)) +
  geom_bar(stat = "identity")+
  ylab("Seconds of Mammal Activity per Trap Night")+
  xlab("Month (2022)")+
  theme_classic()
          
seasonal_activity_plot
```


## Let's visualize rough community composition a couple different ways:
### First, activity by species across the study standardized by effort (trap nights)
```{r adjusted sp observations}

IDcolors <- alphabet.colors(15)
#swatch(IDcolors)
names(IDcolors) <- NULL # necessary for ggplot to remove the names so it can assign colors correctly?

spp_seasonal_activity_plot <- activity_site_month_sp %>% 
  mutate(month = month(month, label = TRUE)) %>% 
  group_by(month, common_name) %>% 
  summarize(spp_activity = sum(seconds_by_trapnight)) %>% 
  ggplot(., aes(x = month, y = spp_activity)) +
    geom_bar(aes(fill = common_name),
           stat = "identity")+
  scale_fill_manual(values = IDcolors)+
  ylab("Activity Seconds Per Trap Night") +
  xlab("Month (2022)") +
  theme_classic()

spp_seasonal_activity_plot

```
 
Robin: you might see a coyote every day, but you'll also see a pig a day and there's 12 of them

### Then, standardized activity by species but represented as a percentage of the total community
```{r}

spercent_seasonal_activity_plot <- activity_site_month_sp %>% 
  mutate(month = month(month, label = TRUE)) %>% 
  group_by(month, common_name) %>% 
  summarize(spp_activity = sum(seconds_by_trapnight)) %>% 
  ggplot(., aes(x = month, y = spp_activity)) +
    geom_bar(aes(fill = common_name), 
             position = "fill", #makes percent stacked
             stat = "identity")+
  scale_fill_manual(values = IDcolors)+
  ylab("Percent of Total Animal Activity (Seconds)")+
  xlab("Month (2022") +
  guides(fill=guide_legend(title = "Mammal Species"))+
  theme_classic()

spercent_seasonal_activity_plot

png(here("figures/seasonal_community_shift.png"), width = 10, height = 8, units = "in", pointsize = 12, res = 1000)
spercent_seasonal_activity_plot
dev.off()
```

### Then, standardized activity by species in space
```{r}
 # colors for plotting

spercent_space_activity <- activity_site_month_sp %>% 
  group_by(property, sitename, common_name) %>% 
  summarize(spp_activity = sum(seconds_by_trapnight)) %>%  
  ungroup() %>% 
  mutate(sitename = fct_relevel(sitename, c("Boathouse Cam", "Ladrones Cam", "Saucito Cam", "Water Canyon Cam", "Not Water Canyon Cam", "Morida Cam","RIZ Cam", "RIZ Cam Backup", "RIZ Cam S Canyon", "Sudden Canyon Cam", "Old Fencepost Cam", "Jolluru Cam", "Short Canyon Cam", "Jalama Cam", "Jalama 2 Cam", "Cojalama Cam", "Cojo Gate Cam", "Cojo Canyon Cam", "Seawall Cam", "Black Canyon Cam", "North Beach Fort Cam", "North Vista Spring Cam", "North Beach Canyon Cam", "Boneyard Cam", "Cove Cam", "Govies Cliff Cam", "Big Cojo Cam", "Percos Boat Cam", "Percos Driftwood Cam", "Wood Canyon Cam", "Percos Beach Cam", "Percos Log Cam", "Percos Post Cam", "Damsite Creek Cam"))) %>%
  mutate(colorz = case_when(property == "JBCP" ~ "red",
                            property == "JLDP" ~ "green",
                            property == "VSFB" ~ "blue"))

spercent_space_activity_plot <- ggplot(spercent_space_activity, aes(x = sitename, y = spp_activity)) +
    geom_bar(aes(fill = common_name), 
             position = "fill", #makes percent stacked
             stat = "identity")+
  scale_fill_manual(values = IDcolors)+
  ylab("Percent of Total Animal Activity (Seconds)")+
  xlab("Camera Station (North to South)")+
  theme_classic()+
  theme(axis.text.x = element_text(#colour = spercent_space_activity$colorz, # makes text different colors based on property NOT WORKING EVEN WITH ELEMENT_MARKDOWN
                                   angle = 45, 
                                   hjust = 1, 
                                   size = 7
                                   ), 
        axis.text.y = element_text(size = 10),
        axis.title.y = element_text(size = 10)
        )+
  guides(fill=guide_legend(title = "Mammal Species"))
  

spercent_space_activity_plot

png(here("figures/spatial_community_shift.png"), width = 10, height = 8, units = "in", pointsize = 12, res = 1000)
spercent_space_activity_plot
dev.off()
```

## Now we are ready to use vegan to calculate a bunch of community ecology metrics - the below taken from An Bui's vegan workshop.

### vegan analysis with site metadata from: https://docs.google.com/spreadsheets/d/1F1pI3ORnCh-Zq6jd1Y11ThUozsBy3iryT9zxW7QCeVY/edit?usp=sharing
```{r reshape data for vegan}
#######################################
# get in shape for vegan (wide)      #
#######################################

# WAS using count_species_site and adjusting using burst_settings from metadata
# switched to using activity_site_month_sp because it has all of the grouping variables used
# need to get clean dataset into sitemonth as rownames and column headers as species with counts in cells

count_matrix <- count_species_site %>% 
  
#  # here's where we should take out "mammal" and "carnivorous mammal"
  filter(common_name != "unidentified mammal") %>% 
  
  left_join(., metadata, by = join_by(sitename)) %>%
  filter(!is.na(property)) %>%  # this means they didn't match up to existing metadata and should be left out (filters out bad deployments)
  dplyr::select(sitename, common_name, n_images) %>% 
  
  pivot_wider(names_from = common_name, # makes 'common_name' col into col headers
              values_from = n_images, # and pulls counts from n col
              values_fill = 0) %>%  # fills in zeros to the matrix
  column_to_rownames("sitename")  #this is important for separating site names from count data (for matrix reasons)


#########################################################################################
# make new metadata set so that binning by month and averaging by site is possible      #
#########################################################################################
count_matrix_expanded <- activity_site_month_sp %>% 
  ungroup() %>% 
  
  # here's where we should take out "mammal" and "carnivorous mammal"
  filter(common_name != "unidentified mammal") %>% 
  dplyr::select(sitemonth_id, common_name, activity_seconds) %>% # sitemonth_id is like a sample id, adjusted captures is the images/burst settings
  
  pivot_wider(names_from = common_name, # makes 'common_name' col into col headers
              values_from = activity_seconds, # and pulls counts from n col
              values_fill = 0)  %>%  # fills in zeros to the matrix
  column_to_rownames("sitemonth_id")  #this is important for separating site names from count data (for matrix reasons)

#########################################################################################
#            make another matrix with 'counts' adjusted for effort for bray-curtis      #
#########################################################################################

count_matrix_byeffort <- activity_site_month_sp %>% 
  ungroup() %>% 
  
  # here's where we should take out "mammal" and "carnivorous mammal"
  filter(common_name != "unidentified mammal") %>% 
  group_by(sitename, common_name) %>% # adjusted seconds by site and species
  summarise(seconds_by_trapnight = sum(seconds_by_trapnight)) %>% 
  
  pivot_wider(names_from = common_name, # makes 'common_name' col into col headers
              values_from = seconds_by_trapnight, # and pulls counts from n col
              values_fill = 0)  %>%  # fills in zeros to the matrix
  column_to_rownames("sitename")  #this is important for separating site names from count data (for matrix reasons)
  
```

### How speciose are my communities?
- one caveat: we lumped all rats & mice into one "species" because they're super hard to tell apart with cam trap footage
```{r richness}
# we can use vegan to count species per site using specnumber() but we need to change the format to wide first

sp.count <- specnumber(count_matrix_expanded)
sp.freq <- specnumber(count_matrix_expanded, MARGIN = 2) # relative frequency of each sp. compared to others

sp_df <- sp.count %>% 
  # convert named vector to dataframe
  enframe() %>% 
  rename(sitemonth_id = name) %>% 
  left_join(., metadata_by_month, by = join_by(sitemonth_id)) # add variables back on from the monthly metadata sheet

sp_df$sitename <- factor(sp_df$sitename, levels = c("Boathouse Cam", "Ladrones Cam", "Saucito Cam", "Water Canyon Cam", "Not Water Canyon Cam", "Morida Cam","RIZ Cam", "RIZ Cam Backup", "RIZ Cam S Canyon", "Sudden Canyon Cam", "Old Fencepost Cam", "Jolluru Cam", "Short Canyon Cam", "Jalama Cam", "Jalama 2 Cam", "Cojalama Cam", "Cojo Gate Cam", "Cojo Canyon Cam", "Seawall Cam", "Black Canyon Cam", "North Beach Fort Cam", "North Vista Spring Cam", "North Beach Canyon Cam", "Boneyard Cam", "Cove Cam", "Govies Cliff Cam", "Big Cojo Cam", "Percos Boat Cam", "Percos Driftwood Cam", "Wood Canyon Cam", "Percos Beach Cam", "Percos Log Cam", "Percos Post Cam", "Damsite Creek Cam"))

species_plot <- ggplot(sp_df, aes(x= sitename, y = value)) +
                       #aes(x = landtype, y = mean, fill = landtype)) +
  geom_boxplot(aes(fill = property))+
  theme_classic()+  
  ylab("Mean Species Richness")+
  xlab("Sites North to South")+
  theme(
        axis.text.x = element_text(angle = 45, hjust = 1, size = 7),
        axis.text.y = element_text(size = 10),
        axis.title.y = element_text(size = 10),
        axis.title.x = element_text(size = 10))
species_plot

```


### How diverse are my communities?
```{r diversity}

# vegan::diversity() will calculate shannon (default), simpson, and fisher indices
shannondiv <- diversity(count_matrix) # going to use the original matrix becuase the bunches of zeros are throwing off the means
# again creates named vector 

```

```{r shannon-diversity-plot}
shandiv_df <- shannondiv %>% 
  # convert named vector to dataframe
  enframe() %>% 
  rename(sitename = name) %>% 
  
# join with metadata: this joins shandiv_df to site_type matching shandiv_df$name to site_type$site
  full_join(., metadata_by_month, by = join_by(sitename)) %>% 
  # then calculate mean diversity for each site
  group_by(property, sitename) %>% 
  summarize(mean_shandiv = mean(value))

shandiv_df$sitename <- factor(shandiv_df$sitename, levels = c("Boathouse Cam", "Ladrones Cam", "Saucito Cam", "Water Canyon Cam", "Not Water Canyon Cam", "Morida Cam","RIZ Cam", "RIZ Cam Backup", "RIZ Cam S Canyon", "Sudden Canyon Cam", "Old Fencepost Cam", "Jolluru Cam", "Short Canyon Cam", "Jalama Cam", "Jalama 2 Cam", "Cojalama Cam", "Cojo Gate Cam", "Cojo Canyon Cam", "Seawall Cam", "Black Canyon Cam", "North Beach Fort Cam", "North Vista Spring Cam", "North Beach Canyon Cam", "Boneyard Cam", "Cove Cam", "Govies Cliff Cam", "Big Cojo Cam", "Percos Boat Cam", "Percos Driftwood Cam", "Wood Canyon Cam", "Percos Beach Cam", "Percos Log Cam", "Percos Post Cam", "Damsite Creek Cam"))

shandiv_plot <- ggplot(shandiv_df, 
                       aes(x= sitename, y = mean_shandiv)) +
  geom_col(aes(fill = property))+
  theme_classic()+  
  ylab("Shannon Diversity Index")+
  xlab("Sites North to South")+
  theme(
        axis.text.x = element_text(angle = 45, hjust = 1, size = 7),
        axis.text.y = element_text(size = 10),
        axis.title.y = element_text(size = 10),
        axis.title.x = element_text(size = 10))
#shandiv_plot
shandiv_plot
```

### Is there a correlation between diversity index and human activity?
caveat: we have a crazy outlier of human activity at Jalama - over 3000 "human seconds" where most are in the hundreds
including one plot with raw human activity and one with log transformed

```{r humans and shannon}
#source("DataWrangling/human_count_script.R") # a lil script i wrote to get the human data into a nice neat little summary table of human seconds by site. it's called hooman_count

#humancount_spring <- hooman_count %>% 
#  filter(date == "10may22" | date == "14may22" | date == "17apr22" | date == "28apr22" | date == "5apr22") %>% 
#  # we only wnt human counts that match the current timeline we're working with, may and april
#  mutate(site = case_when(
#    site == "perb" ~ "pb",
#    site == "gc" ~ "gov",
#    site == "gc2" ~ "gov",
#    TRUE ~ site
#  )) %>% 
#  filter(!is.na(site)) %>% 
#  group_by(site) %>% 
#  summarise(human = sum(n)) 

shandiv_humans <- shannondiv %>% 
  # convert named vector to dataframe
  enframe() %>% 
  rename(sitename = name) %>% 
  
# join with metadata: this joins shandiv_df to site_type matching shandiv_df$name to site_type$site
  full_join(., metadata_by_month, by = join_by(sitename)) %>% 
  mutate(standardized_humans = human_seconds/days_per_month) %>% 
  group_by(property, value, sitename) %>% # value is shandiv index
  summarise(human_seconds = sum(standardized_humans))

# plotting scatter to see if there's a relationship

human_scatter <- ggplot(shandiv_humans, aes(x = human_seconds, y = value))+
  geom_point(aes(colour = property))+
  theme_classic()+  
  ylab("Shannon Diversity Index")+
  xlab("Seconds of Human Activity per Trap Night")

# outlier makes this terrible so log transforming human activity

scatter_logt <- ggplot(shandiv_humans, aes(log10(human_seconds), value))+
  geom_point(aes(colour = property))+
  theme_classic()+  
  ylab("Shannon Diversity Index")+
  xlab("Log Transformed Seconds of Human Activity")

human_scatter
scatter_logt
```


### How different are my communities in species composition?

#### perMANOVA
Permutational analysis of variance: are the centroids of my communities different?
```{r mammal-permanova}
# for ANOVA we need multiple samples per 'bin' so need to group by deployment name so we can average by site

# i think i'm just going to have to force a metadata frame that has the same length as the matrix

vegan_metadata <- rownames(count_matrix_expanded) %>%  # extracts the rownames in the right order
    enframe() %>%  # makes a vector into a df
    rename(sitemonth_id = value) %>% 
    left_join(metadata_by_month, by = join_by(sitemonth_id)) %>% 
    drop_na()

# vegan::adonis() takes the same input format as stats::aov() = response ~ IV, data = group_df
mammal_perm <- adonis2(count_matrix_expanded ~ sitename, data = vegan_metadata)
mammal_perm
```
Looks like they are. 

#### Bray-Curtis Dissimiliarity based on counts at each site
```{r bray curtis}
#Gower, Bray–Curtis, Jaccard and Kulczynski indices are good in detecting underlying ecological gradients (Faith et al. 1987). Morisita, Horn–Morisita, Binomial, Cao and Chao indices should be able to handle different sample sizes (Wolda 1981, Krebs 1999, Anderson & Millar 2004), OR:
# Cao index or CYd index (Cao et al. 1997) was suggested as a minimally biased index for high beta diversity and variable sampling intensity. Cao index does not have a fixed upper limit, but can vary among sites with no shared species. The index is intended for count (integer) data, and it is undefined for zero abundances; these are replaced with arbitrary value 0.1 following Cao et al. (1997). Cao et al. (1997) used log 10, but the current function uses natural logarithms so that the values are approximately 2.30 times higher than with 10-based logarithms. Anderson & Thompson (2004) give an alternative formulation of Cao index to highlight its relationship with Binomial index (above).

# bray curtis assumes equal sampling effort, so we need to use the adjusted by trap night counts

```


```{r PCA, eval=FALSE, include=FALSE}
#Ordination: each species is an axis along which your sites fall. Ordination compresses all these axes into 2
#There are many different ways to do this math (most of which require multiple samples per habitat type and we only have one sample per site)

#### PCA

#There are as many PCs as there are columns in your matrix, but you can plot as many as you want... best to see what you can do with 2 or maybe 3 for best visualization


# Principal components analysis = a rotation of axes
# redundancy analysis (rda) is an unconstrained ordination - the variation based ONLY on species data
# a constrained ordination would ask how env variables shape community composition
mammalPCA <- rda(count_matrix_byeffort) #no env variables in here, but expanded matrix lets us see how points cluster in space and time
mammalPCA
# pay attention to the inertia term in output - inertia is all the variation in community composition that exists in your dataset

summary(mammalPCA)
# this gives a big output of where species fall in the ordination (species scores and site scores) as well as importance of components - again components are made up just of spp abundances

pca_biplot <- biplot(mammalPCA)
# this plot is not necessarily that informative
# str(pcabiplot) : you have coordinates for points and for ends of arrows

# can extract informative info from the biplot
PCAscores <- as.data.frame(pca_biplot$sites) %>% # it's called sites, not sitename
  bind_cols(metadata2)
  #bind_cols(vegan_metadata, .) # only use if using expanded dataframe

PCAvect <- as.data.frame(pca_biplot$species) # called species, not common_name


PCA_plot <- ggplot(PCAscores) +
  geom_point(aes(x = PC1, y = PC2, 
                 color = property
                 )) +
  geom_segment(data = PCAvect, aes(x = 0, y = 0, xend = PC1, yend = PC2), #make segements coming out from origin
               arrow = arrow(length = unit(0.2, "cm"))) + #arrow length indicates contribution to component
              # sharp angle between arrows indicates correlation between species; 90 deg -> independence
  geom_text(data = PCAvect, aes(x = PC1, y = PC2, label = rownames(PCAvect)))

PCA_plot #expects linear response of species abundance to env variables - not always a valid assumption
```

```{r mammalNMDS, eval=FALSE, include=FALSE}
#### NMDS

#Non-metric Multidimensional Scaling

#Good for nonlinear responses (eg a unimodal response)
#How might communities separate according to their dissimilarity to each other?
#NMDS is again collapsing variation into two axes but slightly differently than PCA

#Construct dissimilarity matrix (species ~ site -> site ~ site); then use the dissimilarity as input to ordination space

#default dissimilarity measure is bray-curtis distance - use the one that makes most sense for your data

#
mammal_NMDS <- metaMDS(count_matrix_byeffort, k = 2, # k is the number of dimensions
                       distance = "cao") # cao is robust against differing sampling effort, but i've standardized sampling effort so is this redundant? it improved MDS performance

mammal_NMDS

plot(mammal_NMDS) #circles are sites (communities/rows), crosses are species
  #NMDS is a mapping not a rotation - axes don't matter wrt variation, etc - it's just a framework
  #for describing dissimilarity between communities

stressplot(mammal_NMDS)
#stress = how far the community moves from its original state in dissimilarity
#this output is not ideal - too much stress

```


```{r NMDS-plot, eval=FALSE, include=FALSE}
# exracting outputs
nmds_df <- as_tibble(mammal_NMDS$points) %>% 
  # bind with metadata to plot
  bind_cols(metadata2, .)

nmds_plot <- ggplot(nmds_df, aes(x = MDS1, y = MDS2, color = habitat_adjacent, shape = habitat_adjacent)) +
  geom_point(size = 3, alpha = 0.8) +
  stat_ellipse()
nmds_plot
#all 3 habitats have different habitat structures but lots of overlap...
# ?betadisper should always be used to check assumptions of nmds (?)
```





```{r subsampled-NMDS, eval=FALSE, include=FALSE}
##### Things to consider about stress
sub <- birds[sample(nrow(birds), 20), ]
subNMDS <- metaMDS(sub)
stressplot(subNMDS) #this subsample brings the stress level down to something that would be acceptable for this ordination
```



```{r bird-CCA, eval=FALSE, include=FALSE}
### How is community structure related to specific environmental variables?

# Canonical correspondence analysis
# only shows variation in communities based on environmental variables
# like a hypothesis test for what you think is most likely to contribute to variation - don't just throw all the variables in
# good place to try several models and do model selection?
birdCCA <- cca(birds ~ canopy_height + stems_ha + big_stem_bas, data = env)
birdCCA

#again, measure of inertia (amt of variation in community composition)
#compare constrained and unconstrained inertia

```

```{r bird-CCA-plot, eval=FALSE, include=FALSE}
ccaplot <- plot(birdCCA)
#this plot reads similar to PCA - x, y axes are the two components that describe most variation and arrows describe how communities might separate along env variables

# scaling factor is taken from structure of plot str(ccaplot) $biplot
ccavectors <- as.data.frame(ccaplot$biplot * 7.69) #scaling factor will change based on the size of your R window / plot output

#coordinates from sites and species from biplot output
site_data <- as.data.frame(ccaplot$sites) %>% 
  bind_cols(site_type, .)

species_data <- as.data.frame(ccaplot$species)

cca_plot <- ggplot(site_data) +
  geom_point(aes(x = CCA1, y = CCA2, color = landtype), shape = 19) +
  geom_segment(data = ccavectors, aes(x = 0, y = 0, xend = CCA1, yend = CCA2), arrow = arrow(length = unit(0.2, "cm"))) +
 # scale_x_continuous(limits = c(-10, 16)) + #these cut off part of the plot - comment them out to fix error
 # scale_y_continuous(limits = c(-3, 12)) +
  geom_point(data = species_data, aes(x = CCA1, y = CCA2), shape = 17, size = 2, color = "blue") +
  geom_text(data = ccavectors, aes(x = CCA1, y = CCA2, label = rownames(ccavectors)))
cca_plot

#length of arrows indicates relative importance to the ordination - here stem basal area is more important than canopy height or stems per hectare
#direction of the arrows indicates correlation between variables
#location of sites/species related to arrows is more important now: more stems/ha in dry sites, taller canopies in riparian sites
```

```{r graveyard, eval=FALSE, include=FALSE}
# graveyard #
# for my edification, I want to know how many trap days per camera (below is months bc im messing around)



humans <- read_csv(here("data/human_activity.csv")) %>% 
  mutate(site = case_when(site == "cove" ~ "Cove",
                          .default = as.character(site))) # I'm sure there are more errors
```


```{r graveyard richness, eval=FALSE, include=FALSE}

## How speciose are my communities? (with reductive count matrix)
#- one caveat: we lumped all rats & mice into one "species" because they're super hard to tell apart with cam trap footage
# we can use vegan to count species per site using specnumber() but we need to change the format to wide first

sp.count <- specnumber(count_matrix)
sp.freq <- specnumber(count_matrix, MARGIN = 2) # relative frequency of each sp. compared to others

sp_df <- sp.count %>% 
  # convert named vector to dataframe
  enframe() %>% 
  rename(sitename = name) %>% 
  left_join(., metadata, by = join_by(sitename)) # add variables back on 

sp_df$sitename <- factor(sp_df$sitename, levels = c("Boathouse Cam", "Ladrones Cam", "Saucito Cam", "Water Canyon Cam", "Not Water Canyon Cam", "Morida Cam","RIZ Cam", "RIZ Cam Backup", "RIZ Cam S Canyon", "Sudden Canyon Cam", "Old Fencepost Cam", "Jolluru Cam", "Short Canyon Cam", "Jalama Cam", "Jalama 2 Cam", "Cojalama Cam", "Cojo Gate Cam", "Cojo Canyon Cam", "Seawall Cam", "Black Canyon Cam", "North Beach Fort Cam", "North Vista Spring Cam", "North Beach Canyon Cam", "Boneyard Cam", "Cove Cam", "Govies Cliff Cam", "Big Cojo Cam", "Percos Boat Cam", "Percos Driftwood Cam", "Wood Canyon Cam", "Percos Beach Cam", "Percos Log Cam", "Percos Post Cam", "Damsite Creek Cam"))

species_plot <- ggplot(sp_df, 
                       aes(x= sitename, y = value)) +
                       #aes(x = landtype, y = mean, fill = landtype)) +
  geom_col(aes(fill = property))+
  theme_classic()+  
  ylab("Species Richness")+
  xlab("Sites North to South")+
  theme(
        axis.text.x = element_text(angle = 45, hjust = 1, size = 7),
        axis.text.y = element_text(size = 10),
        axis.title.y = element_text(size = 10),
        axis.title.x = element_text(size = 10))
species_plot

```